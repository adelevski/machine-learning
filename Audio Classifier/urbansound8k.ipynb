{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import IPython.display as ipd\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import librosa\r\n",
    "import librosa.display\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from scipy.io import wavfile as wav\r\n",
    "import os\r\n",
    "\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras import activations\r\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_path = '/content/UrbanSound8K/audio'\r\n",
    "df = pd.read_csv(\"/content/UrbanSound8K/metadata/UrbanSound8K.csv\")\r\n",
    "labels = list(df['class'].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "files = dict()\r\n",
    "for i in range(len(labels)):\r\n",
    "    tmp = df[df['class'] == labels[i]][:1].reset_index()\r\n",
    "    path = f\"/content/UrbanSound8K/audio/fold{tmp['fold'][0]}/{tmp['slice_file_name'][0]}\"\r\n",
    "    files[labels[i]] = path"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(15,15))\r\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\r\n",
    "for i, label in enumerate(labels):\r\n",
    "    fn = files[label]\r\n",
    "    fig.add_subplot(5, 2, i+1)\r\n",
    "    plt.title(label)\r\n",
    "    data, sample_rate = librosa.load(fn)\r\n",
    "    librosa.display.waveplot(data, sr= sample_rate)\r\n",
    "plt.savefig('class_examples.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fn = '/content/UrbanSound8K/audio/fold1/191431-9-0-66.wav'\r\n",
    "librosa_audio, librosa_sample_rate = librosa.load(fn)\r\n",
    "scipy_sample_rate, scipy_audio = wav.read(fn)\r\n",
    "\r\n",
    "print(f\"Original sample rate: {scipy_sample_rate}\")\r\n",
    "print(f\"Librosa sample rate: {librosa_sample_rate}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f\"Original audio fil min~max range: {np.min(scipy_audio)} to {np.max(scipy_audio)}\")\r\n",
    "print(f\"Librosa audio file min~max range: {np.min(librosa_audio):.2f} to {np.max(librosa_audio):.2f}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 4))\r\n",
    "plt.plot(scipy_audio)\r\n",
    "plt.savefig('original_audio.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 4))\r\n",
    "plt.plot(librosa_audio)\r\n",
    "plt.savefig('librosa_audio.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc=40)\r\n",
    "mfccs.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8, 8))\r\n",
    "librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')\r\n",
    "plt.savefig('MFCCs.png')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_features(file_name):\r\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\r\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\r\n",
    "    mfccs_processed = np.mean(mfccs.T, axis=0)\r\n",
    "\r\n",
    "    return mfccs_processed\r\n",
    "\r\n",
    "def extract(row):\r\n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath), 'fold' + str(row['fold']) + '/', str(row['slice_file_name']))\r\n",
    "    class_label = row['class']\r\n",
    "    data = extract_features(file_name)\r\n",
    "    features.append([data, class_label])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features = []\r\n",
    "df.apply(lambda row: extract(row), axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "featuresdf = pd.DataFrame(features, columns=['feature', 'class_label'])\r\n",
    "featuresdf.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = np.array(featuresdf.feature.to_list())\r\n",
    "y = np.array(featuresdf.class_label.to_list())\r\n",
    "\r\n",
    "le = LabelEncoder()\r\n",
    "yy = to_categorical(le.fit_transform(y))\r\n",
    "\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 127)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "num_labels = yy.shape[1]\r\n",
    "filter_size = 2\r\n",
    "def build_model_graph(input_shape=(40,)):\r\n",
    "    model = tf.keras.Sequential()\r\n",
    "    model.add(layers.Dense(256, input_shape=input_shape))\r\n",
    "    model.add(layers.Activation(activations.relu))\r\n",
    "    model.add(layers.Dropout(0.5))\r\n",
    "    model.add(layers.Dense(256))\r\n",
    "    model.add(layers.Activation(activations.relu))\r\n",
    "    model.add(layers.Dropout(0.5))\r\n",
    "    model.add(layers.Dense(num_labels))\r\n",
    "    model.add(layers.Activation(activations.softmax))\r\n",
    "    # Compile\r\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "model = build_model_graph()\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
    "accuracy = 100*score[1]\r\n",
    "print(f\"Pre-training accuracy: {accuracy:.4f}%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.callbacks import ModelCheckpoint\r\n",
    "from datetime import datetime\r\n",
    "\r\n",
    "num_epochs = 100\r\n",
    "num_batch_size = 32\r\n",
    "\r\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluating the model on the training and testing set\r\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\r\n",
    "print(f\"Training accuracy: {score[1]:.2%}\")\r\n",
    "\r\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
    "print(f\"Testing accuracy: {score[1]:.2%}\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}